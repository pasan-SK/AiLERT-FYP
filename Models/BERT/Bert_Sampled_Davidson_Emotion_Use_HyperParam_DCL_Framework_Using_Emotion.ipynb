{"cells":[{"cell_type":"markdown","metadata":{"id":"H8LlNprqVf-e"},"source":["# Importing Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"sQYVzwmPPO5N","outputId":"dd01d754-1e10-4902-a135-b6ae523a9d3a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n","Collecting evaluate\n","  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m543.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting datasets>=2.0.0 (from evaluate)\n","  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m977.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.25.2)\n","Collecting dill (from evaluate)\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m768.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.2)\n","Collecting xxhash (from evaluate)\n","  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m595.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from evaluate)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m375.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.20.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.0)\n","Collecting responses<0.19 (from evaluate)\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.10.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n","Installing collected packages: xxhash, dill, responses, multiprocess, datasets, evaluate\n","Successfully installed datasets-2.18.0 dill-0.3.8 evaluate-0.4.1 multiprocess-0.70.16 responses-0.18.0 xxhash-3.4.1\n","Collecting accelerate\n","  Downloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->accelerate)\n","  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n","  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n"]}],"source":["!pip install transformers\n","!pip install evaluate\n","!pip install accelerate -U\n","!pip install torchmetrics\n","!pip install optuna\n","!pip install -U \"neptune[optuna]\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DhBv7znKPWf1"},"outputs":[],"source":["import os\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoModel,AutoTokenizer\n","from tqdm import tqdm\n","import evaluate\n","from datasets import load_dataset\n","from tqdm.auto import tqdm\n","import numpy as np\n","import random\n","import pandas as pd\n","from sklearn.utils import shuffle\n","from torchmetrics.classification import BinaryAccuracy,BinaryConfusionMatrix,BinaryF1Score,BinaryPrecision,BinaryRecall, MulticlassPrecision,MulticlassRecall,MulticlassF1Score\n","from torchmetrics.collections import MetricCollection\n","from google.colab import userdata\n","import neptune\n","import neptune.integrations.optuna as npt_utils\n","from neptune.types import File\n","import time"]},{"cell_type":"markdown","metadata":{"id":"LfdjDQRGiiwD"},"source":["# Setting up the GPU or CPU"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pNLafgjrijy7"},"outputs":[],"source":["os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","os.environ[\"NEPTUNE_API_TOKEN\"] = userdata.get('NEPTUNE_API_TOKEN')\n","device = torch.device(\"cuda:0\"  if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"X6Bss8vmWJOM"},"source":["# Define Variable Values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3b3VUKVJizHP"},"outputs":[],"source":["# @title Define Transformer Model Name\n","bert_model_name = \"bert-base-cased\" # @param {type:\"string\"}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o6t8YE-HWReL"},"outputs":[],"source":["# @title Define Hugging Face Dataset Name\n","dataset_name = \"Thushalya/Davidson_Sampled_With_Emotion\" # @param {type:\"string\"}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bkBs6keDioqT"},"outputs":[],"source":["#@title Define Transformer Model Tokenizer Max Padding Length\n","SEED = 1234\n","PADDING_MAX_LENGTH = 45 # @param {type:\"integer\"}"]},{"cell_type":"markdown","metadata":{"id":"vALRUeEfVkZV"},"source":["#Configuring Neptuna"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UCDv1vyx4mkP"},"outputs":[],"source":["# @title Define Neptuna Project Name,Study ID and Best Trial ID\n","study_id = \"FYPTHUS-1818\" # @param {type:\"string\"}\n","trial_id = \"FYPTHUS-1868\" # @param {type:\"string\"}\n","project_name='FYP-DCL/fyp-thushalya'# @param {type:\"string\"}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jUUdSsnC777L"},"outputs":[],"source":["# @title Define Neptuna DCL Project Name & Study Id\n","dcl_study_id='DVRANDOS-10' # @param {type:\"string\"}\n","best_trial_id='DVRANDOS-59' # @param {type:\"string\"}\n","dcl_project_name='pasansk/DCL-DV-RandOverSampler'# @param {type:\"string\"}"]},{"cell_type":"markdown","metadata":{"id":"n0aemVMh2UId"},"source":["##Load the Study Run"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KnFs880H2XWC"},"outputs":[],"source":["run_study = neptune.init_run(with_id=study_id,project=project_name)"]},{"cell_type":"markdown","metadata":{"id":"cKxSg6JF2YFb"},"source":["## Load the Best Trial Run"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gy4i2Mjr2b39"},"outputs":[],"source":["run_trial = neptune.init_run(with_id=trial_id,project=project_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c6J4ZB_y75ny"},"outputs":[],"source":["best_prams=run_trial[\"parameters\"].fetch()"]},{"cell_type":"markdown","metadata":{"id":"Lgdhzculitfy"},"source":["# Setting Random Seed for Reproducibility"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ppI0D_stchR"},"outputs":[],"source":["def setup_seed(seed:int):\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    torch.backends.cudnn.deterministic = True\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TXflz7C-iuDr"},"outputs":[],"source":["setup_seed(SEED)"]},{"cell_type":"markdown","metadata":{"id":"JN5cAM4gi2eZ"},"source":["# Loading Test Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AlVYc1VdtYth"},"outputs":[],"source":["dataset = load_dataset(dataset_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bxxVYTVltnBD"},"outputs":[],"source":["dataset"]},{"cell_type":"markdown","metadata":{"id":"1djnIXHai7J3"},"source":["# Loading the Tokernizer for the Transformer Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kTEhbiFoi7wk"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(bert_model_name)"]},{"cell_type":"markdown","metadata":{"id":"byzLJSHYXd7F"},"source":["##Define the Tokenizer Function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yio7aiUai_Yp"},"outputs":[],"source":["def tokenize_function(examples):\n","    return tokenizer.batch_encode_plus(examples[\"text\"], padding='max_length',max_length=PADDING_MAX_LENGTH,add_special_tokens=True,truncation=True)"]},{"cell_type":"markdown","metadata":{"id":"HfUlH-6SjCdP"},"source":["## Tokenize the Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WN0mJKzQjDau"},"outputs":[],"source":["tokenized_datasets = dataset.map(tokenize_function, batched=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"auXuLtTY8mUw"},"outputs":[],"source":["# Define a function to merge columns into a list\n","def merge_emotion_columns_to_list(example):\n","    return {'emotion_vector': [example['anger'], example['anticipation'], example['disgust'],example['fear'],example['joy'],example['love'],example['optimism'],example['pessimism'],example['sadness'],example['surprise'],example['trust']]}\n","\n","# Apply the function to each example in the dataset\n","tokenized_datasets = tokenized_datasets.map(merge_emotion_columns_to_list)"]},{"cell_type":"markdown","metadata":{"id":"H80ECEiRjCXo"},"source":["## Remove Unwanted Coloumns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OpUvx3hfjKRi"},"outputs":[],"source":["tokenized_datasets=tokenized_datasets.remove_columns(['text','anger', 'anticipation', 'disgust', 'fear', 'joy', 'love', 'optimism', 'pessimism', 'sadness', 'surprise', 'trust'])"]},{"cell_type":"markdown","metadata":{"id":"yUrvQSIfjNYL"},"source":["## Format the coloumns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6_EJBG1YjOEN"},"outputs":[],"source":["tokenized_datasets=tokenized_datasets.with_format(\"torch\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fXJwia8Efwqm"},"outputs":[],"source":["tokenized_datasets"]},{"cell_type":"markdown","metadata":{"id":"FSlxzFEyjRVB"},"source":["# Creating DataLoaders for Train & Test Datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9qycWMxuGWgo"},"outputs":[],"source":["train_dataloader=DataLoader(tokenized_datasets[\"train\"], batch_size=best_prams[\"BATCH_SIZE\"] , shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V47AijTUjVUX"},"outputs":[],"source":["test_dataloader=DataLoader(tokenized_datasets[\"test\"], batch_size=best_prams[\"BATCH_SIZE\"] , shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"XfWJrLM0jbqz"},"source":["# Define the Dual Contrastive Learning Architecture"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ki5wFpdmjczU"},"outputs":[],"source":["class DCLArchitecture(nn.Module):\n","    def __init__(self,dropout:float,bert_model_name:str='bert-base-cased'):\n","        super(DCLArchitecture, self).__init__()\n","        self.bert = AutoModel.from_pretrained(bert_model_name)\n","        self.dim = 768\n","        self.dense = nn.Linear(self.dim, 1)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self,batch_tokenized, if_train=False):\n","        input_ids = batch_tokenized['input_ids']\n","        attention_mask = batch_tokenized['attention_mask']\n","        bert_output = self.bert(input_ids, attention_mask=attention_mask, output_hidden_states=True)\n","        bert_cls_hidden_state = bert_output[1]\n","        torch.cuda.empty_cache()\n","\n","        if if_train:\n","            bert_cls_hidden_state_aug = self.dropout(bert_cls_hidden_state)\n","            bert_cls_hidden_state = torch.cat((bert_cls_hidden_state, bert_cls_hidden_state_aug), dim=1).reshape(-1, self.dim)\n","        else:\n","            bert_cls_hidden_state = self.dropout(bert_cls_hidden_state)\n","\n","        linear_output = self.dense(bert_cls_hidden_state)\n","        linear_output = linear_output.squeeze(1)\n","\n","        return bert_cls_hidden_state, linear_output"]},{"cell_type":"markdown","metadata":{"id":"75utt_iVjhFx"},"source":["## Define Focal Loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"STWD75vgjgcP"},"outputs":[],"source":["class FocalLoss(nn.Module):\n","    def __init__(self, alpha:float=0.4, gamma:float=2, size_average:bool=True):\n","        super(FocalLoss, self).__init__()\n","        self.alpha = torch.tensor(alpha)\n","        self.gamma = gamma\n","        self.size_average = size_average\n","\n","    def forward(self, pred, target):\n","\n","        device = target.device\n","        self.alpha = self.alpha.to(device)\n","\n","        pred = nn.Sigmoid()(pred)\n","        pred = pred.view(-1, 1)\n","        target = target.view(-1, 1)\n","        pred = torch.cat((1-pred, pred), dim=1)\n","\n","        class_mask = torch.zeros(pred.shape[0], pred.shape[1]).to(device)\n","        class_mask.scatter_(1, target.view(-1, 1).long(), 1.)\n","        probs = (pred * class_mask).sum(dim=1).view(-1, 1)\n","        probs = probs.clamp(min=0.0001, max=1.0)\n","\n","        log_p = probs.log()\n","        alpha = torch.ones(pred.shape[0], pred.shape[1]).to(device)\n","        alpha[:, 0] = alpha[:, 0] * (1 - self.alpha)\n","        alpha[:, 1] = alpha[:, 1] * self.alpha\n","        alpha = (alpha * class_mask).sum(dim=1).view(-1, 1)\n","\n","        batch_loss = -alpha * (torch.pow((1 - probs), self.gamma)) * log_p\n","\n","        if self.size_average:\n","            loss = batch_loss.mean()\n","        else:\n","            loss = batch_loss.sum()\n","\n","        return loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AGGJBtzK8t2I"},"outputs":[],"source":["class EmotionGuidedDCLModel(nn.Module):\n","    def __init__(self,dcl_model:nn.Module,dropout:float=0.25):\n","        super(EmotionGuidedDCLModel, self).__init__()\n","        self.dcl_model = dcl_model\n","        self.dim = 779\n","        self.dropout = nn.Dropout(dropout)\n","        self.linear = nn.Linear(self.dim, 1)\n","        # Freeze all layers\n","        for param in self.dcl_model.parameters():\n","            param.requires_grad = False\n","\n","    def forward(self,batch_tokenized):\n","        input_ids = batch_tokenized['input_ids']\n","        attention_mask = batch_tokenized['attention_mask']\n","        emotion_vector = batch_tokenized['emotion_vector']\n","        bert_output = self.dcl_model(input_ids, attention_mask=attention_mask, output_hidden_states=True)\n","        bert_cls_hidden_state = bert_output[1]\n","        combined_vector =torch.cat((bert_cls_hidden_state,emotion_vector), 1)\n","        d_combined_vector=self.dropout(combined_vector)\n","        linear_output = self.linear(d_combined_vector)\n","        pred_linear = linear_output.squeeze(1)\n","        return pred_linear"]},{"cell_type":"markdown","metadata":{"id":"fC2OGx9MHeN-"},"source":["#Configuring the Model & Focal Loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F7L8s9y28yKQ"},"outputs":[],"source":["run_dcl_study = neptune.init_run(with_id=dcl_study_id,project=dcl_project_name,mode='read-only')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K9Dw3FGw8zlZ"},"outputs":[],"source":["run_best_model_trial = neptune.init_run(with_id=best_trial_id,project=dcl_project_name,mode=\"read-only\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vGwpO7nd81FX"},"outputs":[],"source":["best_prams=run_best_model_trial[\"parameters\"].fetch()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BmbWOFiy83ZO"},"outputs":[],"source":["def load_checkpoint(run: neptune.Run,check_point_name:str):\n","    model_ext = run[check_point_name][\"model\"].fetch_extension()\n","    run[check_point_name][\"model\"].download()  # Download the checkpoint\n","    run.wait()\n","    # Load the checkpoint\n","    checkpoint = {\n","        \"model_state_dict\":torch.load(f\"model.{model_ext}\"),\n","    }\n","    return checkpoint"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kfHZOucN85V5"},"outputs":[],"source":["checkpoint=load_checkpoint(run=run_dcl_study,check_point_name=\"model_checkpoints/\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aR1MTK8U87IB"},"outputs":[],"source":["dcl_model = DCLArchitecture(bert_model_name=bert_model_name,dropout=best_prams[\"DROPOUT\"])\n","dcl_model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YnAThbSH88tC"},"outputs":[],"source":["dcl_model.load_state_dict(checkpoint[\"model_state_dict\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hCrybzO58-cJ"},"outputs":[],"source":["run_dcl_study.stop()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EdTa69Qs8__m"},"outputs":[],"source":["run_best_model_trial.stop()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hpoI65_o9CCM"},"outputs":[],"source":["fined_tuned_bert_model=dcl_model.bert"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"weamdjxD9EIf"},"outputs":[],"source":["DROPOUT = 0.5\n","model = EmotionGuidedDCLModel(dcl_model=fined_tuned_bert_model,dropout=DROPOUT)\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Ll2G9CJ4u5-"},"outputs":[],"source":["optimizer = torch.optim.AdamW(model.parameters(),lr = best_prams[\"LEARNING_RATE\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wBxmL_mPHnUf"},"outputs":[],"source":["criteon = FocalLoss(best_prams[\"ALPHA\"],best_prams[\"GAMMA\"])"]},{"cell_type":"markdown","metadata":{"id":"2frED-w_HX3A"},"source":["#Training the Model"]},{"cell_type":"markdown","metadata":{"id":"wcWhQdRiG2AB"},"source":["## Define Training Loop"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wi-GKjBYG2nk"},"outputs":[],"source":["def training_loop(model, train_dataloader,optimizer,criteon,device):\n","    accuracy_metric = BinaryAccuracy()\n","    accuracy_metric.to(device)\n","    progress_bar = tqdm(range(len(train_dataloader)))\n","    model.train()\n","    total_train_loss = 0.0\n","    for batch in train_dataloader:\n","        batch = {k: v.to(device) for k, v in batch.items()}\n","        labels = batch['labels']\n","        pred = model(batch)\n","        loss = criteon(pred, labels.float())\n","        total_train_loss += loss.item()\n","        loss_value=loss.item()\n","        pred_sig = torch.sigmoid(pred)\n","        preds_detach=torch.round(pred_sig.detach())\n","        accuracy_metric(preds_detach,labels)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        progress_bar.update(1)\n","    average_epoch_train_loss = total_train_loss / len(train_dataloader)  # Compute average epoch loss\n","    train_accuracy =  accuracy_metric.compute()\n","    accuracy_metric.reset()\n","    return average_epoch_train_loss,train_accuracy.item()"]},{"cell_type":"markdown","metadata":{"id":"w_wARUsKI6td"},"source":["##Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wj6NotDMH81X"},"outputs":[],"source":["for epoch in range(best_prams[\"EPOCHS\"]):\n","        start_time = time.time()\n","        average_epoch_train_loss,train_accuracy = training_loop(model, train_dataloader,optimizer,criteon,device)\n","        end_time = time.time()\n","\n","        epoch_mins, epoch_secs = divmod(end_time - start_time, 60)\n","        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs:.2f}s')\n","        print(f'\\tTrain Loss: {average_epoch_train_loss:.3f} | Train Acc: {train_accuracy*100:.2f}%')\n"]},{"cell_type":"markdown","metadata":{"id":"wsoo9Gm3kB0n"},"source":["# Evaluate with Test Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SaHndSmFkCsp"},"outputs":[],"source":["def test_loop(model, test_dataloader,criteon, device,average:str=\"macro\"):\n","    collection_metric = MetricCollection(\n","          BinaryAccuracy(),\n","          MulticlassPrecision(num_classes=2,average=average),\n","          MulticlassRecall(num_classes=2,average=average),\n","          MulticlassF1Score(num_classes=2,average=average),\n","    )\n","    collection_metric.to(device)\n","    bcm_metric = BinaryConfusionMatrix()\n","    bcm_metric.to(device)\n","    model.eval()\n","    total_test_loss = 0.0\n","    for batch in test_dataloader:\n","        batch = {k: v.to(device) for k, v in batch.items()}\n","        labels = batch[\"labels\"]\n","        with torch.no_grad():\n","            pred = model(batch)\n","            loss = criteon(pred, labels.float())\n","            pred = torch.round(torch.sigmoid(pred))\n","        total_test_loss += loss.item()\n","        collection_metric(pred,labels)\n","        bcm_metric(pred,labels)\n","    average_epoch_test_loss = total_test_loss / len(test_dataloader)  # Compute average epoch loss\n","    result =  collection_metric.compute()\n","    bcm_metric.compute()\n","    collection_metric.reset()\n","    result['Loss']=average_epoch_test_loss\n","    result['confustion_matrix'],_=bcm_metric.plot()\n","    bcm_metric.reset()\n","    return result"]},{"cell_type":"markdown","metadata":{"id":"K63UySiI3Wfr"},"source":["## Test the model with Test Set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ga8UQq1_kLQz"},"outputs":[],"source":["result_metrics=test_loop(model, test_dataloader,criteon, device,average=\"weighted\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NigPkLTlXSkt"},"outputs":[],"source":["result_metrics"]},{"cell_type":"markdown","metadata":{"id":"ZpiSM0GW3fw6"},"source":["## Upload the Test Results to Neptuna"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R3dpnsRaTJ10"},"outputs":[],"source":["def upload_test_metrics(result,run: neptune.Run):\n","    run[\"Test_Result/Accuracy\"]=result[\"BinaryAccuracy\"]\n","    run[\"Test_Result/Loss\"]=result[\"Loss\"]\n","    run[\"Test_Result/weighted_Precision\"]=result[\"MulticlassPrecision\"]\n","    run[\"Test_Result/weighted_Recall\"]=result[\"MulticlassRecall\"]\n","    run[\"Test_Result/weighted_F1Score\"]=result[\"MulticlassF1Score\"]\n","    run[\"Test_Result/confustion_matrix\"].upload(result[\"confustion_matrix\"])\n","    run.wait()\n","    print(\"Upload Succesfull\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TIPZ_CE83eIk"},"outputs":[],"source":["upload_test_metrics(result_metrics,run_study)"]},{"cell_type":"markdown","metadata":{"id":"Q365pou0xris"},"source":["# Save the Model Checkpoint"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vDuKSaTfxsO_"},"outputs":[],"source":["def save_model_states(model,criteon,optimizer):\n","    torch.save(model.state_dict(),'model.pt')\n","    torch.save(criteon.state_dict(),'criteon.pt')\n","    torch.save(optimizer.state_dict(),'optimizer.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BU5wKHp5xxLX"},"outputs":[],"source":["def upload_model_checkpoint(directory:str,run: neptune.Run):\n","    run[f\"{directory}/model\"].upload('model.pt')\n","    run[f\"{directory}/criteon\"].upload('criteon.pt')\n","    run[f\"{directory}/optimizer\"].upload('optimizer.pt')\n","    run.wait()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K2RjC1qbxzNP"},"outputs":[],"source":["save_model_states(model=model,criteon=criteon,optimizer=optimizer)\n","upload_model_checkpoint(run=run_study,directory=\"model_checkpoints\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7I7YstLNUceh"},"outputs":[],"source":["run_trial.stop()\n","run_study.stop()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}