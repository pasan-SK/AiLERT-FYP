{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Owner\\anaconda3\\envs\\emotion\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset_name = \"krishan-CSE/HatEval-Relabeled\"\n",
    "dataset = load_dataset(dataset_name)\n",
    "\n",
    "df_train = dataset['train'].to_pandas()\n",
    "df_valid = dataset['validation'].to_pandas()\n",
    "df_test = dataset['test'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9088, 2)\n",
      "train value_counts:\n",
      " labels\n",
      "0    4811\n",
      "1    4277\n",
      "Name: count, dtype: int64\n",
      "                                                text  labels\n",
      "0  This human-elephant conflict has seen 13 refug...       0\n",
      "1  The awkward moment when Lexus is showing you h...       0\n",
      "2            People- why are you so fucking mean Me-       0\n",
      "3  After EU uses Turkey as buffer to stop refugee...       0\n",
      "4                           Immigration in a picture       0\n",
      "====================================================================================\n",
      "(1168, 2)\n",
      "validation value_counts:\n",
      " labels\n",
      "0    618\n",
      "1    550\n",
      "Name: count, dtype: int64\n",
      "                                                text  labels\n",
      "0  President Jokowi: it's not true millions of Ch...       0\n",
      "1  So you created the problem by mass immigration...       1\n",
      "2  I though in a free country you could worship w...       0\n",
      "3  WELP. Bitch IM JUST NOW FUCKING SEEING DUMB WHORE       1\n",
      "4  .Considering THIS , the filth on the streets o...       1\n",
      "====================================================================================\n",
      "(2724, 2)\n",
      "test value_counts:\n",
      " labels\n",
      "0    1442\n",
      "1    1282\n",
      "Name: count, dtype: int64\n",
      "                                                text  labels\n",
      "0  We have got to get these Obama DACA illegal al...       1\n",
      "1  The same bitch is all on my boos shit like gir...       0\n",
      "2  BS WILSON IS A SKANK WHORE AND A LIAR . DIDDN'...       1\n",
      "3  Immigration Expert: Trudeau Has Lost Track Of ...       1\n",
      "4  I like to delete comments that say 'first' to ...       0\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(\"train value_counts:\\n\", df_train['labels'].value_counts())\n",
    "print(df_train.head())\n",
    "print(\"==========================================\"\n",
    "      \"==========================================\")\n",
    "print(df_valid.shape)\n",
    "print(\"validation value_counts:\\n\", df_valid['labels'].value_counts())\n",
    "print(df_valid.head())\n",
    "print(\"==========================================\"\n",
    "      \"==========================================\")\n",
    "print(df_test.shape)\n",
    "print(\"test value_counts:\\n\", df_test['labels'].value_counts())\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modfied from code by Kwan-Yuet (Stephen) Ho:\n",
    "# https://datawarrior.wordpress.com/2016/03/29/flesch-kincaid-readability-measure/\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import cmudict\n",
    "import nltk\n",
    "# from common import getCorpusJson\n",
    "# from features.feature import Feature\n",
    "nltk.download('cmudict', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "\n",
    "# class FleschKincaid(Feature):\n",
    "def FleschKincaid(text: str) -> float:\n",
    "  word_count, sent_count, syllable_count = text_statistics(text)\n",
    "  return fk_formula(word_count, sent_count, syllable_count)\n",
    "\n",
    "\n",
    "# class Flesch(Feature):\n",
    "def Flesch(text: str) -> float:\n",
    "  word_count, sent_count, syllable_count = text_statistics(text)\n",
    "  return flesch_formula(word_count, sent_count, syllable_count)\n",
    "\n",
    "\n",
    "# class WordCount(Feature):\n",
    "def WordCount(text: str) -> float:\n",
    "  return float(get_word_count(text))\n",
    "\n",
    "\n",
    "# class SentenceCount(Feature):\n",
    "def SentenceCount(text: str) -> float:\n",
    "  return float(get_sent_count(text))\n",
    "\n",
    "\n",
    "# class SyllableCount(Feature):\n",
    "def SyllableCount(text: str) -> float:\n",
    "  return float(get_syllable_count(text))\n",
    "\n",
    "# private\n",
    "def not_punctuation(w): return not (len(w) == 1 and (not w.isalpha()))\n",
    "\n",
    "# private\n",
    "def get_word_count(text: str):\n",
    "  return len(\n",
    "      list(filter(not_punctuation, word_tokenize(text))))\n",
    "\n",
    "# private\n",
    "def get_sent_count(text): return len(sent_tokenize(text))\n",
    "\n",
    "\n",
    "prondict = cmudict.dict()\n",
    "\n",
    "\n",
    "def numsyllables_pronlist(l): return len(\n",
    "    list(filter(lambda s: (s[-1]).isdigit(), l)))\n",
    "\n",
    "\n",
    "def numsyllables(word):\n",
    "  try:\n",
    "    return list(set(map(numsyllables_pronlist, prondict[word.lower()])))\n",
    "  except KeyError:\n",
    "    return [0]\n",
    "\n",
    "# private\n",
    "def text_statistics(text):\n",
    "  word_count = get_word_count(text)\n",
    "  sent_count = get_sent_count(text)\n",
    "  syllable_count = sum(\n",
    "      map(\n",
    "          lambda w: max(\n",
    "              numsyllables(w)),\n",
    "          word_tokenize(text)))\n",
    "  return word_count, sent_count, syllable_count\n",
    "\n",
    "\n",
    "def get_syllable_count(text):\n",
    "  return sum(\n",
    "      map(\n",
    "          lambda w: max(\n",
    "              numsyllables(w)),\n",
    "          word_tokenize(text)))\n",
    "\n",
    "# private\n",
    "def flesch_formula(word_count, sent_count, syllable_count): return 206.835 - \\\n",
    "    1.015 * word_count / sent_count - 84.6 * syllable_count / word_count\n",
    "\n",
    "# private\n",
    "def fk_formula(word_count, sent_count, syllable_count): return 0.39 * \\\n",
    "    word_count / sent_count + 11.8 * syllable_count / word_count - 15.59\n",
    "\n",
    "\n",
    "def syllablesPerWord(text):\n",
    "  word_count, sent_count, syllable_count = text_statistics(text)\n",
    "  return syllable_count / word_count\n",
    "\n",
    "\n",
    "def avgSenLength(text):\n",
    "  word_count, sent_count, syllable_count = text_statistics(text)\n",
    "  return word_count / sent_count\n",
    "\n",
    "\n",
    "def wordCount(text):\n",
    "  word_count, sent_count, syllable_count = text_statistics(text)\n",
    "  return word_count\n",
    "\n",
    "\n",
    "def sent_count(text):\n",
    "  word_count, sent_count, syllable_count = text_statistics(text)\n",
    "  return sent_count\n",
    "\n",
    "\n",
    "def syllable_count(text):\n",
    "  word_count, sent_count, syllable_count = text_statistics(text)\n",
    "  return syllable_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FlenshKincaid: -1.1923076923076916\n",
      "Flesch: 111.32897435897436\n",
      "WordCount: 13.0\n",
      "SentenceCount: 3.0\n",
      "SyllableCount: 14.0\n",
      "syllablesPerWord: 1.0769230769230769\n",
      "avgSenLength: 4.333333333333333\n",
      "wordCount: 13\n",
      "sent_count: 3\n",
      "syllable_count: 14\n"
     ]
    }
   ],
   "source": [
    "tweet = \"Excited for the conference! @user1@user4, @user2, and @user3 will be presenting. #ConferenceTime\"\n",
    "print(\"FlenshKincaid:\", FleschKincaid(tweet))\n",
    "print(\"Flesch:\", Flesch(tweet))\n",
    "print(\"WordCount:\", WordCount(tweet))\n",
    "print(\"SentenceCount:\", SentenceCount(tweet))\n",
    "print(\"SyllableCount:\", SyllableCount(tweet))\n",
    "print(\"syllablesPerWord:\", syllablesPerWord(tweet))\n",
    "print(\"avgSenLength:\", avgSenLength(tweet))\n",
    "print(\"wordCount:\", wordCount(tweet))\n",
    "print(\"sent_count:\", sent_count(tweet))\n",
    "print(\"syllable_count:\", syllable_count(tweet))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn textblob nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Extract features and target variable\n",
    "X = df_train.drop('labels', axis=1)\n",
    "y = df_train['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "9083    1\n",
       "9084    1\n",
       "9085    0\n",
       "9086    1\n",
       "9087    1\n",
       "Name: labels, Length: 9088, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define a function to extract features from a single tweet\n",
    "def extract_features(tweet):\n",
    "    features = {\n",
    "        'FleschKincaid': FleschKincaid(tweet),\n",
    "        'Flesch': Flesch(tweet),\n",
    "        'WordCount': WordCount(tweet),\n",
    "        'SentenceCount': SentenceCount(tweet),\n",
    "        'SyllableCount': SyllableCount(tweet),\n",
    "        'syllablesPerWord': syllablesPerWord(tweet),\n",
    "        'avgSenLength': avgSenLength(tweet),\n",
    "        'wordCount': wordCount(tweet),\n",
    "        'sent_count': sent_count(tweet),\n",
    "        'syllable_count': syllable_count(tweet)\n",
    "    }\n",
    "    return features\n",
    "\n",
    "# Extract features for all tweets\n",
    "features_list = [extract_features(tweet) for tweet in X['text']]\n",
    "\n",
    "# Create a Pandas DataFrame\n",
    "X_new = pd.DataFrame(features_list)\n",
    "\n",
    "# # Add the labels to the DataFrame\n",
    "# df['Label'] = labels\n",
    "\n",
    "# # Display the DataFrame\n",
    "# print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FleschKincaid</th>\n",
       "      <th>Flesch</th>\n",
       "      <th>WordCount</th>\n",
       "      <th>SentenceCount</th>\n",
       "      <th>SyllableCount</th>\n",
       "      <th>syllablesPerWord</th>\n",
       "      <th>avgSenLength</th>\n",
       "      <th>wordCount</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>syllable_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.725263</td>\n",
       "      <td>80.686842</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.263158</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.616471</td>\n",
       "      <td>85.074118</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.235294</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.145000</td>\n",
       "      <td>124.690000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.004444</td>\n",
       "      <td>38.960000</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.444444</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.570000</td>\n",
       "      <td>33.575000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9083</th>\n",
       "      <td>8.895238</td>\n",
       "      <td>68.691429</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.380952</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9084</th>\n",
       "      <td>-0.093333</td>\n",
       "      <td>117.105000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9085</th>\n",
       "      <td>5.141765</td>\n",
       "      <td>78.384608</td>\n",
       "      <td>34.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.382353</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9086</th>\n",
       "      <td>3.838095</td>\n",
       "      <td>104.948571</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9087</th>\n",
       "      <td>2.940000</td>\n",
       "      <td>85.858333</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9088 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      FleschKincaid      Flesch  WordCount  SentenceCount  SyllableCount  \\\n",
       "0          6.725263   80.686842       19.0            1.0           24.0   \n",
       "1          5.616471   85.074118       17.0            1.0           21.0   \n",
       "2         -2.145000  124.690000        8.0            1.0            7.0   \n",
       "3         19.004444   38.960000       45.0            1.0           65.0   \n",
       "4          9.570000   33.575000        4.0            1.0            8.0   \n",
       "...             ...         ...        ...            ...            ...   \n",
       "9083       8.895238   68.691429       21.0            1.0           29.0   \n",
       "9084      -0.093333  117.105000       12.0            1.0           11.0   \n",
       "9085       5.141765   78.384608       34.0            3.0           47.0   \n",
       "9086       3.838095  104.948571       21.0            1.0           20.0   \n",
       "9087       2.940000   85.858333       20.0            3.0           27.0   \n",
       "\n",
       "      syllablesPerWord  avgSenLength  wordCount  sent_count  syllable_count  \n",
       "0             1.263158     19.000000         19           1              24  \n",
       "1             1.235294     17.000000         17           1              21  \n",
       "2             0.875000      8.000000          8           1               7  \n",
       "3             1.444444     45.000000         45           1              65  \n",
       "4             2.000000      4.000000          4           1               8  \n",
       "...                ...           ...        ...         ...             ...  \n",
       "9083          1.380952     21.000000         21           1              29  \n",
       "9084          0.916667     12.000000         12           1              11  \n",
       "9085          1.382353     11.333333         34           3              47  \n",
       "9086          0.952381     21.000000         21           1              20  \n",
       "9087          1.350000      6.666667         20           3              27  \n",
       "\n",
       "[9088 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.59\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.65      0.62       948\n",
      "           1       0.58      0.52      0.55       870\n",
      "\n",
      "    accuracy                           0.59      1818\n",
      "   macro avg       0.59      0.58      0.58      1818\n",
      "weighted avg       0.59      0.59      0.58      1818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We have got to get these Obama DACA illegal al...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The same bitch is all on my boos shit like gir...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BS WILSON IS A SKANK WHORE AND A LIAR . DIDDN'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Immigration Expert: Trudeau Has Lost Track Of ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I like to delete comments that say 'first' to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels\n",
       "0  We have got to get these Obama DACA illegal al...       1\n",
       "1  The same bitch is all on my boos shit like gir...       0\n",
       "2  BS WILSON IS A SKANK WHORE AND A LIAR . DIDDN'...       1\n",
       "3  Immigration Expert: Trudeau Has Lost Track Of ...       1\n",
       "4  I like to delete comments that say 'first' to ...       0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.56\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.61      0.59      1442\n",
      "           1       0.53      0.49      0.51      1282\n",
      "\n",
      "    accuracy                           0.56      2724\n",
      "   macro avg       0.55      0.55      0.55      2724\n",
      "weighted avg       0.55      0.56      0.55      2724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features_list_test = [extract_features(tweet) for tweet in df_test['text']]\n",
    "X_test_new = pd.DataFrame(features_list_test)\n",
    "X_test_scaled = scaler.transform(X_test_new)\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "accuracy_test = accuracy_score(df_test['labels'], y_test_pred)\n",
    "print(f\"Test Accuracy: {accuracy_test:.2f}\")\n",
    "print(\"\\nTest Classification Report:\")\n",
    "print(classification_report(df_test['labels'], y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emotion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
